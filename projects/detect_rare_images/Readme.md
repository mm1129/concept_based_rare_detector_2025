## Supported Features

- **Object Detection & Cropping:**  
  Detect objects within images using YOLO (Ultralytics) and crop the detected objects for further analysis.

- **Feature Extraction:**  
  Extract image and text embeddings using the CLIP model.

- **Outlier Detection & Visualization:**  
  Utilize t-SNE to visualize high-dimensional features in 2D, comparing baseline images with new images, and apply IsolationForest to identify outliers. These results are combined to generate a final outlier code.

- **Image Captioning:**  
  Generate descriptive captions for images using GPT-4o via the OpenAI API.

- **Result Visualization & Storage:**  
  Save processing outputs (plots, cropped images, description text files, and similarity bar charts) in designated folders.

## Setup

1. Install all required libraries:

   ```
   pip install ultralytics transformers openai torch scikit-learn matplotlib Pillow python-dotenv
   ```
   or simply
```
docker build -t rare .
docker run -it --rm --shm-size=64g -v "$PWD":/workspace -v /mnt/HDD16TB/dataset/external/nuscenes:/workspace/data_nuscenes rare
```

2. Create a `.env` file in the project root and set your OpenAI API key:

   ```
   OPENAI_API_KEY=your_api_key_here
   ```

## Usage

1. Execute the `main()` function in `whole-architecture.py` to train the baseline model and detect new images:

   ```
   python whole-architecture.py
   ```

2. By default, images are read from:
   - Baseline images: `data_nuscenes/nuscenes/samples/CAM_FRONT`
   - New images: `data_nuscenes/nuscenes/samples/CAM_FRONT` (this can be modified as needed)

## Storage Folders and Contents

- **baseline_cropped_objects**  
  → Contains cropped object images extracted from the baseline images using YOLO.

- **Current Directory**  
  - `baseline_tsne.png`  
    → t-SNE visualization plot of the baseline images.
  - `baseline_tsne_class.png`  
    → t-SNE visualization focused on the top 20 classes.

- **out_images**  
  → Stores the t-SNE visualization image (`tsne_visualization.png`) generated by the `visualize_tsne` function.

- **new_cropped_objects**  
  → Contains processed new images, organized into subfolders:
  - `inlier_inlier`: Images classified as inliers by both methods.
  - `if_outlier_only`: Images flagged as outliers only by the IsolationForest.
  - `tsne_outlier_only`: Images flagged as outliers only by t-SNE.
  - `both_outlier`: Images flagged as outliers by both methods.  
  Each subfolder includes copies of the original images, cropped object images, generated description text files (`*_desc.txt`), and similarity bar charts (`*_probs.png`).

- **detected_images**  
  → Contains copies of original images that are classified as outliers (where outlier code ≠ 0).

- **outliner**  
  → A folder created during the outlier detection process.

## Results and Models

- The baseline model training produces detected objects along with their CLIP embeddings and an IsolationForest model.
- Outlier detection on new images results in visualizations and saved outputs as detailed above.

TBD: Additional details on result interpretation, parameter tuning, and further module usage will be added in future updates.


# concept_based_rare_detector
# レア物体判定の詳細について

## レア物体の判定ロジック

このプログラムにおけるレア物体の判定は、以下の2つの条件を両方満たす必要があります：

1. **コンセプトが一般的でないこと**：
   - 物体のキャプションから計算された「最も類似度の高いコンセプト」が、あらかじめ定義された「一般的なクラスのリスト」(`common_classes`)に含まれていないこと
   - 一般的クラスは `["car", "truck", "bus", "pedestrian", "motorcycle", "traffic_cone", "barrier"]` と設定されています

2. **類似度が閾値以上であること**：
   - キャプションとコンセプトの類似度が閾値（デフォルトでは0.25）以上であること
   - この閾値は、キャプションとコンセプトの関連性が十分に高いことを確認するためのものです

具体的には、以下のコード部分で判定しています：
```python
result = {
    # ...その他の情報...
    "is_rare": top_concept not in common_classes and top_similarity > similarity_threshold
}

if result["is_rare"]:
    rare_objects.append(result)
    # レア物体として処理...
```

## 結果の保存について

処理結果は以下のファイルとディレクトリに保存されます：

### 1. メインの出力ディレクトリ
`rare_objects_MMDD`というディレクトリが作成されます（MMDDは実行日の月日）。

### 2. 画像と物体の分類ディレクトリ
- `rare_objects_MMDD/rare/` - レアと判定された物体の画像
- `rare_objects_MMDD/common/` - 一般的と判定された物体の画像
- `rare_objects_MMDD/crops/` - 元画像から切り出された全物体の画像

### 3. JSONファイル
- `rare_objects_MMDD/rare_objects_MMDD.json` - レア物体の詳細情報（元画像パス、物体クラス、信頼度、キャプション、類似度など）

### 4. テキストファイル
レア物体ごとに情報テキストファイルが作成されます：
- `rare_objects_MMDD/rare/[画像名]_info.txt` - 物体の詳細情報（元画像、クラス、キャプション、トップコンセプト、類似度など）

### 5. 可視化結果
- `rare_objects_MMDD/rare_concepts_distribution.png` - レアコンセプトの分布グラフ
- `rare_objects_MMDD/similarity_distribution.png` - 類似度スコアの分布ヒストグラム
- `rare_objects_MMDD/tsne_visualization.png` - レア物体と一般物体の埋め込みをt-SNEで2次元可視化した散布図

これらの出力により、レアと判断された物体がどのようなものか、視覚的にも数値的にも分析できるようになっています。また、各画像が「なぜレアと判定されたのか」を後から確認することも可能です。